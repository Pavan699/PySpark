# PySpark
CPU-Logs problem solved using the pyspark

version - spark-3.1.2                

Hadoop version  - hadoop-3.2.2

Step 1 - Importing findspark and initializing connection

Step 2 - Creating the sparksession by using  SparkSession.builder.getOrCreate() builder class

Step 3 - reading all the csv files and adding data in one dataframe

Step 4 - Getting the counts for the users and plot for the same

Step 5 - Calculationg hightest and lowest (working)avg hours from all users

Step 6 - Calculationg hightest and lowest ideal user from all users
